{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "173217d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_json('aspen.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90a3970b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "#pre-processing of text\n",
    "import string\n",
    "import re\n",
    "\n",
    "\n",
    "from nltk import word_tokenize, pos_tag\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0643eff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the lists in 'hotel' column to strings\n",
    "df['hotel'] = df['hotel'].apply(lambda x: x[0])  # Convert list to string\n",
    "df['content'] = df['content'].apply(lambda x: x[0]) \n",
    "# Combine 'hotel' and 'clear_text' into a single column\n",
    "df['combined'] = df['hotel'] + \":\\n\"  + df['content']\n",
    "\n",
    "# Drop the original columns if needed\n",
    "#df.drop(['hotel', 'content'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2753b3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['combined']= df['combined'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8ec58e5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2006"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['combined'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "378946c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras module for building LSTM \n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import Sequential\n",
    "import keras.utils as ku \n",
    "\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string, os \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5f5c2ce4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['limelight hotel\\nwent on a girls trip this past weekend we had a wonderful time and the hotel was amazing everyone from the front desk to the shuttle drivers to the bartenders and kitchen staff were fantastic the breakfast and warm cookies were a delicious touch also we will definitely be back next year for more fun',\n",
       " 'limelight hotel\\nwe were very lucky to win 4 nights accomodation at the limelight hotel and we stayed an extra 4 nights to make a full week of skiing  it was our 7th trip to aspen but our first at the limelight and it was brilliant  the staff were helpful friendly and fun and our room over looking rugby park was large and roomy with plenty of space for ski gear and the bed was very very comfortable  breakfast was included and covered just about all the food groups including fresh fruit  happy hour from 37 was so good with great cocktails and the pizzas were the best ever  the hot tubs and pool were just the thing after a day skiing  we noticed that the rooms were extremely quiet and the fridge and heating system was a lot quieter than the hotel we stayed at in canyons utah',\n",
       " 'chateau roaring fork\\nwait until the last minute and get a lodginglift ticket package through resortquest that cant be beat',\n",
       " 'limelight hotel\\ngreat hotel beautiful great well decorated bar and nice lounge area with fun cocktails and other drinks live music with great talent rooms are spacious and nicely decorated super comfy bed and outstanding customer service looking forward to another stay',\n",
       " 'aspen mountain lodge\\ngreat value decent location id highly recommend a room on the top floor with a balcony unless you want to feel claustrophobic we had a bottom floor aka basement room in a corner that had no windows we liked the free parking lot and free breakfast the people were nice rooms seemed clean enough the whole lodge is very open with a large communal room in the middle so you will see your neighbors and their dogs walking around overall great if youre on a tight budget',\n",
       " 'hearthstone house\\nhad a family reunion there three siblings and significant others  it was fabulous  breakfast cooked up by tyler each morning  wine and cheese served in the afternoon  shannon the manager was very helpful with everything  rooms were a little noisy with street traffic but the fan in the room helped drown out the noise  a very comfortable and relaxed atmosphere within walking distance to lots of restaurants',\n",
       " 'limelight hotel\\nthe limelight aspen exceeded all of our expectations for our time in aspen over new years  it is a family friendly hotel but was still nice clean and wellappointed for adults that appreciate an upscale hotel  first of all im sure that this week is the most busy of the entire year but we never once had to wait to speak with the front desk for an elevator for gym equipment for a drinkfood at breakfast etc which was a miracle  this speaks in my opinion to the great service and staff  everyone was super helpful  we had our 75 month baby with us and everyone on the staff went out of their way to greet him and help us with anything we needed including providing a car seat for our airport pickup and drop off  our room was great  on the 3rd floor with a great view of the park and the mountains beyond  we loved watching the dogs run around the park in the snow  we were honestly shocked at how spacious the room was with plenty of room for us to spread out and for the baby to have room to play  fireplace and bar area in the room were great touches plus ample storage for all of our stuff and as anyone traveling with a baby knows it is a lot of stuff  the room was clean and updated as well  food in the lounge was great  breakfast was of great variety and all was good  i was surprised by how great the afternoondinner offerings were  we ate dinner at the hotel our first night and did to go in our room on the last night  everything was delicious   i also appreciated the various green practices featured by the hotel  from lights and fireplaces on timers to amenities in pumps vs tiny plastic bottles  very thoughtful without taking away from convenience or comfort the one and only negative feature of our entire experience there has to be one right was that noise from the hallway carried so loudly  there were kids running up and down the hall screaming and knocking on each others doors and i lived in fear that it was going to wake up the baby at night  it was not that there was noise from the adjacent rooms just from the hallway so i wonder if the doors could be sealed better  all in all i was originally disappointed that we wouldnt be staying at the little nell but after staying at limelight this week i cannot imagine having done anything differently  this hotel met all of our needs and then some and i am so glad we stayed here',\n",
       " 'the prospector condominiums\\nyou cant beat the location or the price on these condos each featuring a wood burning fireplace and a private hot tub  literally just steps from the aspen walking mall  unobstructed views of aspen mtn as the rugby field is situated between the condo and the mtn  this is a fractional ownership property that rents as a hotel as well  underground covered parking as well as onsight laundry facilities too',\n",
       " 'aspen mountain lodge\\nwe were traveling with another couple and at the last minute decided to stay in aspen where we have visited before  we were very pleased that we could book two rooms  staff was very friendly our rooms were very comfortable the location was good and the breakfast was much better than most motels offer we would definitely stay there again   ric and muriel',\n",
       " 'hearthstone house\\nthe hotel is located very near the heart of aspen the room was below average in size and faced a busy intersection although the air at night was cool the noise  from the intersection dictated that the windows had to be closed and with no airconditioning it was a little warm the location only a couple of blocks from the heart of aspen afforded a good opportunity to walk throughout the city since it was too early for snow the town was not busy in activity we ate our evening meal at la fondue the onion soup was excellant as were the lemon crepes with two glases of wine it was surprisingly expensive the breakfast was very good with eggs to order as well as continental brekfast the price for overnight was reasonable ']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_text(txt):\n",
    "    txt = \"\".join(v for v in txt if v not in string.punctuation).lower()\n",
    "    txt = txt.encode(\"utf8\").decode(\"ascii\",'ignore')\n",
    "    return txt \n",
    "\n",
    "corpus = [clean_text(x) for x in df['combined']]\n",
    "corpus[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9c4a8767",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[306, 13],\n",
       " [306, 13, 207],\n",
       " [306, 13, 207, 27],\n",
       " [306, 13, 207, 27, 3],\n",
       " [306, 13, 207, 27, 3, 1011],\n",
       " [306, 13, 207, 27, 3, 1011, 154],\n",
       " [306, 13, 207, 27, 3, 1011, 154, 19],\n",
       " [306, 13, 207, 27, 3, 1011, 154, 19, 461],\n",
       " [306, 13, 207, 27, 3, 1011, 154, 19, 461, 286],\n",
       " [306, 13, 207, 27, 3, 1011, 154, 19, 461, 286, 8]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "\n",
    "def get_sequence_of_tokens(corpus):\n",
    "    ## tokenization\n",
    "    tokenizer.fit_on_texts(corpus)\n",
    "    total_words = len(tokenizer.word_index) + 1\n",
    "    \n",
    "    ## convert data to sequence of tokens \n",
    "    input_sequences = []\n",
    "    for line in corpus:\n",
    "        token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "        for i in range(1, len(token_list)):\n",
    "            n_gram_sequence = token_list[:i+1]\n",
    "            input_sequences.append(n_gram_sequence)\n",
    "    return input_sequences, total_words\n",
    "\n",
    "inp_sequences, total_words = get_sequence_of_tokens(corpus)\n",
    "inp_sequences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a9140a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_padded_sequences(input_sequences):\n",
    "    max_sequence_len = max([len(x) for x in input_sequences])\n",
    "    input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
    "    \n",
    "    predictors, label = input_sequences[:,:-1],input_sequences[:,-1]\n",
    "    label = ku.to_categorical(label, num_classes=total_words)\n",
    "    return predictors, label, max_sequence_len\n",
    "\n",
    "predictors, label, max_sequence_len = generate_padded_sequences(inp_sequences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d94da9fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 552, 10)           82230     \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 100)               44400     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 100)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 8223)              830523    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 957153 (3.65 MB)\n",
      "Trainable params: 957153 (3.65 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_model(max_sequence_len, total_words):\n",
    "    input_len = max_sequence_len - 1\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Add Input Embedding Layer\n",
    "    model.add(Embedding(total_words, 10, input_length=input_len))\n",
    "    \n",
    "    # Add Hidden Layer 1 - LSTM Layer\n",
    "    model.add(LSTM(100))\n",
    "    model.add(Dropout(0.1))\n",
    "    \n",
    "    # Add Output Layer\n",
    "    model.add(Dense(total_words, activation='softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = create_model(max_sequence_len, total_words)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0cdfc1f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "Epoch 2/5\n",
      "Epoch 3/5\n",
      "Epoch 4/5\n",
      "Epoch 5/5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7ff49ec9b7c0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "%%time\n",
    "model.fit(predictors, label, epochs=5, verbose=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "33318281",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(seed_text, next_words, model, max_sequence_len):\n",
    "    for _ in range(next_words):\n",
    "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "        token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "        predicted = model.predict_classes(token_list, verbose=0)\n",
    "        \n",
    "        output_word = \"\"\n",
    "        for word,index in tokenizer.word_index.items():\n",
    "            if index == predicted:\n",
    "                output_word = word\n",
    "                break\n",
    "        seed_text += \" \"+output_word\n",
    "    return seed_text.title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b50acb65",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Sequential' object has no attribute 'predict_classes'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/tt/kv93hy8d0l5gkhtlnrmv0vjw0000gn/T/ipykernel_9467/1643164507.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgenerate_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"limelight\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_sequence_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/tt/kv93hy8d0l5gkhtlnrmv0vjw0000gn/T/ipykernel_9467/3305427181.py\u001b[0m in \u001b[0;36mgenerate_text\u001b[0;34m(seed_text, next_words, model, max_sequence_len)\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mtoken_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtexts_to_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mseed_text\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mtoken_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtoken_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_sequence_len\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pre'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0moutput_word\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'predict_classes'"
     ]
    }
   ],
   "source": [
    "generate_text(\"limelight hotel\", 5, model, max_sequence_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d750d930",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(seed_text, next_words, model, max_sequence_len, tokenizer):\n",
    "    for _ in range(next_words):\n",
    "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "        token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "        predicted = np.argmax(model.predict(token_list), axis=-1)\n",
    "        \n",
    "        output_word = \"\"\n",
    "        for word, index in tokenizer.word_index.items():\n",
    "            if index == predicted:\n",
    "                output_word = word\n",
    "                break\n",
    "        seed_text += \" \" + output_word\n",
    "    return seed_text.title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c410cbee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The Molly Gibson Lodge  We Stayed At The Molly Gibson Lodge We Stayed At The Molly Gibson Lodge We Had A Great Room With A Great View Of The Hotel And The Hotel Was Very Friendly And Helpful The Staff Was Very Helpful And The Staff Was Very Comfortable'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(\"The Molly Gibson Lodge \", 45, model, max_sequence_len, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c90d619",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
