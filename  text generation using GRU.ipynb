{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c2e3463e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_json('aspen.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "498a003f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "#pre-processing of text\n",
    "import string\n",
    "import re\n",
    "\n",
    "\n",
    "from nltk import word_tokenize, pos_tag\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9d1e1a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the lists in 'hotel' column to strings\n",
    "df['hotel'] = df['hotel'].apply(lambda x: x[0])  # Convert list to string\n",
    "df['content'] = df['content'].apply(lambda x: x[0]) \n",
    "# Combine 'hotel' and 'clear_text' into a single column\n",
    "df['combined'] = df['hotel'] + \":\\n\"  + df['content']\n",
    "\n",
    "# Drop the original columns if needed\n",
    "#df.drop(['hotel', 'content'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d8c57047",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stars</th>\n",
       "      <th>hotel</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>combined</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Limelight Hotel</td>\n",
       "      <td>[Awesome visit ]</td>\n",
       "      <td>Went on a girls trip this past weekend. We had...</td>\n",
       "      <td>Limelight Hotel:\\nWent on a girls trip this pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Limelight Hotel</td>\n",
       "      <td>[Super hotel and Super Staff]</td>\n",
       "      <td>We were very lucky to win 4 nights accomodatio...</td>\n",
       "      <td>Limelight Hotel:\\nWe were very lucky to win 4 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Chateau Roaring Fork</td>\n",
       "      <td>[Wait until the last minute]</td>\n",
       "      <td>Wait until the last minute and get a lodging/l...</td>\n",
       "      <td>Chateau Roaring Fork:\\nWait until the last min...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Limelight Hotel</td>\n",
       "      <td>[Great Hotel. Nice place to stay]</td>\n",
       "      <td>Great hotel. Beautiful. Great well decorated b...</td>\n",
       "      <td>Limelight Hotel:\\nGreat hotel. Beautiful. Grea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>Aspen Mountain Lodge</td>\n",
       "      <td>[Quaint and cozy lodge]</td>\n",
       "      <td>Great value, decent location. I'd highly recom...</td>\n",
       "      <td>Aspen Mountain Lodge:\\nGreat value, decent loc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001</th>\n",
       "      <td>5</td>\n",
       "      <td>Chateau Blanc</td>\n",
       "      <td>[Great stay]</td>\n",
       "      <td>Spent a couple of nights in Aspen on a girls g...</td>\n",
       "      <td>Chateau Blanc:\\nSpent a couple of nights in As...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>4</td>\n",
       "      <td>Chateau Blanc</td>\n",
       "      <td>[Excellent cost/benefit]</td>\n",
       "      <td>We stayed in a two bedrooms/bathrooms apartmen...</td>\n",
       "      <td>Chateau Blanc:\\nWe stayed in a two bedrooms/ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003</th>\n",
       "      <td>5</td>\n",
       "      <td>Chateau Blanc</td>\n",
       "      <td>[Great WInter Vaca]</td>\n",
       "      <td>A wonderful place to stay for our family vacat...</td>\n",
       "      <td>Chateau Blanc:\\nA wonderful place to stay for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td>5</td>\n",
       "      <td>Chateau Blanc</td>\n",
       "      <td>[Chateau Blanc for a week]</td>\n",
       "      <td>The lodge is few blocks away from the main dow...</td>\n",
       "      <td>Chateau Blanc:\\nThe lodge is few blocks away f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005</th>\n",
       "      <td>5</td>\n",
       "      <td>Shadow Mountain Lodge</td>\n",
       "      <td>[Excellent Value]</td>\n",
       "      <td>Great location, nice rooms much larger than a ...</td>\n",
       "      <td>Shadow Mountain Lodge:\\nGreat location, nice r...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2006 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      stars                  hotel                              title  \\\n",
       "0         5        Limelight Hotel                   [Awesome visit ]   \n",
       "1         5        Limelight Hotel      [Super hotel and Super Staff]   \n",
       "2         5   Chateau Roaring Fork       [Wait until the last minute]   \n",
       "3         5        Limelight Hotel  [Great Hotel. Nice place to stay]   \n",
       "4         3   Aspen Mountain Lodge            [Quaint and cozy lodge]   \n",
       "...     ...                    ...                                ...   \n",
       "2001      5          Chateau Blanc                       [Great stay]   \n",
       "2002      4          Chateau Blanc           [Excellent cost/benefit]   \n",
       "2003      5          Chateau Blanc                [Great WInter Vaca]   \n",
       "2004      5          Chateau Blanc         [Chateau Blanc for a week]   \n",
       "2005      5  Shadow Mountain Lodge                  [Excellent Value]   \n",
       "\n",
       "                                                content  \\\n",
       "0     Went on a girls trip this past weekend. We had...   \n",
       "1     We were very lucky to win 4 nights accomodatio...   \n",
       "2     Wait until the last minute and get a lodging/l...   \n",
       "3     Great hotel. Beautiful. Great well decorated b...   \n",
       "4     Great value, decent location. I'd highly recom...   \n",
       "...                                                 ...   \n",
       "2001  Spent a couple of nights in Aspen on a girls g...   \n",
       "2002  We stayed in a two bedrooms/bathrooms apartmen...   \n",
       "2003  A wonderful place to stay for our family vacat...   \n",
       "2004  The lodge is few blocks away from the main dow...   \n",
       "2005  Great location, nice rooms much larger than a ...   \n",
       "\n",
       "                                               combined  \n",
       "0     Limelight Hotel:\\nWent on a girls trip this pa...  \n",
       "1     Limelight Hotel:\\nWe were very lucky to win 4 ...  \n",
       "2     Chateau Roaring Fork:\\nWait until the last min...  \n",
       "3     Limelight Hotel:\\nGreat hotel. Beautiful. Grea...  \n",
       "4     Aspen Mountain Lodge:\\nGreat value, decent loc...  \n",
       "...                                                 ...  \n",
       "2001  Chateau Blanc:\\nSpent a couple of nights in As...  \n",
       "2002  Chateau Blanc:\\nWe stayed in a two bedrooms/ba...  \n",
       "2003  Chateau Blanc:\\nA wonderful place to stay for ...  \n",
       "2004  Chateau Blanc:\\nThe lodge is few blocks away f...  \n",
       "2005  Shadow Mountain Lodge:\\nGreat location, nice r...  \n",
       "\n",
       "[2006 rows x 5 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7aa50d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['combined']= df['combined'].str.lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "efe7d0ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       limelight hotel:\\nwent on a girls trip this pa...\n",
       "1       limelight hotel:\\nwe were very lucky to win 4 ...\n",
       "2       chateau roaring fork:\\nwait until the last min...\n",
       "3       limelight hotel:\\ngreat hotel. beautiful. grea...\n",
       "4       aspen mountain lodge:\\ngreat value, decent loc...\n",
       "                              ...                        \n",
       "2001    chateau blanc:\\nspent a couple of nights in as...\n",
       "2002    chateau blanc:\\nwe stayed in a two bedrooms/ba...\n",
       "2003    chateau blanc:\\na wonderful place to stay for ...\n",
       "2004    chateau blanc:\\nthe lodge is few blocks away f...\n",
       "2005    shadow mountain lodge:\\ngreat location, nice r...\n",
       "Name: combined, Length: 2006, dtype: object"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['combined']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4947706a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined text saved to 'combined_text.txt'\n"
     ]
    }
   ],
   "source": [
    "# Save 'combined' column to a text file\n",
    "df['combined'].to_csv('combined_text.txt', index=False, header=False, sep='\\t')  # Change sep='\\t' to sep=' ' if needed\n",
    "\n",
    "print(\"Combined text saved to 'combined_text.txt'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3a787530",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-16 15:22:59.848714: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "19ac13c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lenght of text: 948809 characters\n"
     ]
    }
   ],
   "source": [
    "text = open(\"combined_text.txt\", 'rb').read().decode(encoding='utf-8')\n",
    "print(f\"Lenght of text: {len(text)} characters\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6f7ea6f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"limelight hotel:\n",
      "went on a girls trip this past weekend. we had a wonderful time and the hotel was amazing. everyone from the front desk to the shuttle drivers to the bartenders and kitchen staff were fantastic. the breakfast and warm cookies were a\n"
     ]
    }
   ],
   "source": [
    "print(text[:250])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5b064582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77 unique characters\n"
     ]
    }
   ],
   "source": [
    "vocab = sorted(set(text))\n",
    "print(f'{len(vocab)} unique characters')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fbd8a1b",
   "metadata": {},
   "source": [
    "### Process the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1f95556e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[b's', b't', b'e', b'f', b'a', b'n'],\n",
       " [b'n', b'a', b'f', b'e', b't', b's']]>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_text = ['stefan', 'nafets']\n",
    "\n",
    "chars = tf.strings.unicode_split(example_text, input_encoding='UTF-8')\n",
    "chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "edf5bacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_from_chars = tf.keras.layers.StringLookup(\n",
    "    vocabulary=list(vocab),\n",
    "    mask_token=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "584aebdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[53, 54, 39, 40, 35, 48],\n",
       " [48, 35, 40, 39, 54, 53]]>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = ids_from_chars(chars)\n",
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a9d435a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars_from_ids = tf.keras.layers.StringLookup(\n",
    "    vocabulary=ids_from_chars.get_vocabulary(),\n",
    "    invert=True,\n",
    "    mask_token=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7bb1e9cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[b's', b't', b'e', b'f', b'a', b'n'],\n",
       " [b'n', b'a', b'f', b'e', b't', b's']]>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars = chars_from_ids(ids)\n",
    "chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c197fd53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b'stefan', b'nafets'], dtype=object)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.reduce_join(chars, axis=1).numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "66698630",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets create a function that we can call later\n",
    "def text_from_ids(ids):\n",
    "  return tf.strings.reduce_join(chars_from_ids(ids), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968a8e96",
   "metadata": {},
   "source": [
    "### The prediciton task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "1099fb04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(948809,), dtype=int64, numpy=array([ 4, 46, 43, ..., 16,  4,  1])>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_ids = ids_from_chars(tf.strings.unicode_split(text, 'UTF-8'))\n",
    "all_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "25a01a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "1f1d5021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"\n",
      "l\n",
      "i\n",
      "m\n",
      "e\n",
      "l\n",
      "i\n",
      "g\n",
      "h\n",
      "t\n"
     ]
    }
   ],
   "source": [
    "for ids in ids_dataset.take(10):\n",
    "  print(chars_from_ids(ids).numpy().decode('UTF-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "cb33948f",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 100\n",
    "examples_per_epoch = len(text) // (seq_length + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b910c933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[b'\"' b'l' b'i' b'm' b'e' b'l' b'i' b'g' b'h' b't' b' ' b'h' b'o' b't'\n",
      " b'e' b'l' b':' b'\\n' b'w' b'e' b'n' b't' b' ' b'o' b'n' b' ' b'a' b' '\n",
      " b'g' b'i' b'r' b'l' b's' b' ' b't' b'r' b'i' b'p' b' ' b't' b'h' b'i'\n",
      " b's' b' ' b'p' b'a' b's' b't' b' ' b'w' b'e' b'e' b'k' b'e' b'n' b'd'\n",
      " b'.' b' ' b'w' b'e' b' ' b'h' b'a' b'd' b' ' b'a' b' ' b'w' b'o' b'n'\n",
      " b'd' b'e' b'r' b'f' b'u' b'l' b' ' b't' b'i' b'm' b'e' b' ' b'a' b'n'\n",
      " b'd' b' ' b't' b'h' b'e' b' ' b'h' b'o' b't' b'e' b'l' b' ' b'w' b'a'\n",
      " b's' b' ' b'a'], shape=(101,), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "sequences = ids_dataset.batch(seq_length + 1, drop_remainder=True)\n",
    "\n",
    "for seq in sequences.take(1):\n",
    "  print(chars_from_ids(seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "3baf9b88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\"limelight hotel:\\nwent on a girls trip this past weekend. we had a wonderful time and the hotel was a'\n",
      "b'mazing. everyone from the front desk to the shuttle drivers to the bartenders and kitchen staff were '\n",
      "b'fantastic. the breakfast and warm cookies were a delicious touch also. we will definitely be back nex'\n",
      "b't year for more fun!\"\\n\"limelight hotel:\\nwe were very lucky to win 4 nights accomodation at the limeli'\n",
      "b'ght hotel and we stayed an extra 4 nights to make a full week of skiing.  it was our 7th trip to aspe'\n"
     ]
    }
   ],
   "source": [
    "for seq in sequences.take(5):\n",
    "  print(text_from_ids(seq).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "30fbb5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_input_target(sequence):\n",
    "  input_text = sequence[:-1]\n",
    "  target_text = sequence[1:]\n",
    "  return input_text, target_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "fb53860d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['T', 'e', 'n', 's', 'o', 'r', 'f', 'l', 'o'],\n",
       " ['e', 'n', 's', 'o', 'r', 'f', 'l', 'o', 'w'])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_input_target(list('Tensorflow'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "492f38f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = sequences.map(split_input_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "1ffdec33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input  : b'\"limelight hotel:\\nwent on a girls trip this past weekend. we had a wonderful time and the hotel was '\n",
      "Target : b'limelight hotel:\\nwent on a girls trip this past weekend. we had a wonderful time and the hotel was a'\n"
     ]
    }
   ],
   "source": [
    "for input_example, target_example in dataset.take(1):\n",
    "  print('Input  :', text_from_ids(input_example).numpy())\n",
    "  print('Target :', text_from_ids(target_example).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "5246e69e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_PrefetchDataset element_spec=(TensorSpec(shape=(63, 100), dtype=tf.int64, name=None), TensorSpec(shape=(63, 100), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Batch size\n",
    "BATCH_SIZE = 63\n",
    "\n",
    "\"\"\"Buffer size to shuffle the dataset\n",
    "(TF data is designed to work wiht possobly infinite sequences,\n",
    "so it dosen't attempt to shuffle the entire sequence in memory. Instadfe\n",
    "it maintaines a buffer is which it shuffles elements)\"\"\"\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "dataset = (\n",
    "    dataset.shuffle(BUFFER_SIZE) \\\n",
    "    .batch(BATCH_SIZE, drop_remainder=True) \\\n",
    "    .prefetch(tf.data.experimental.AUTOTUNE)\n",
    ")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1d539f",
   "metadata": {},
   "source": [
    "### Build The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "412d09df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Length of the vocabulart in chars\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "# The embedding dimension\n",
    "embedding_dim = 256\n",
    "\n",
    "# Number of RNN units\n",
    "rnn_units = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "520cae80",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
    "        super().__init__(self)\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(\n",
    "            rnn_units,\n",
    "            return_sequences=True,\n",
    "            return_state=True\n",
    "        )\n",
    "        self.dense = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "    def call(self, inputs, states=None, return_state=False, training=False):\n",
    "        x = self.embedding(inputs, training=training)\n",
    "        \"\"\"since we are training a text generation model,\n",
    "        we use the previous state, in training. If there is no state,\n",
    "        then we initialize the state \"\"\"\n",
    "        if states is None:\n",
    "            states = self.gru.get_initial_state(x)\n",
    "        x, states = self.gru(x, initial_state=states, training=training)\n",
    "        x = self.dense(x, training=training)\n",
    "\n",
    "        if return_state:\n",
    "            return x, states\n",
    "        else:\n",
    "            return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "597b4555",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, lstm_units):\n",
    "        super().__init__()\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = tf.keras.layers.LSTM(\n",
    "            lstm_units,\n",
    "            return_sequences=True,\n",
    "            return_state=True\n",
    "        )\n",
    "        self.dense = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "    def call(self, inputs, states=None, return_state=False, training=False):\n",
    "        x = self.embedding(inputs, training=training)\n",
    "        \"\"\"由于我们正在训练一个文本生成模型，\n",
    "        我们在训练中使用前一个状态。如果没有状态，\n",
    "        则初始化状态 \"\"\"\n",
    "        if states is None:\n",
    "            # LSTM层会管理自己的初始状态\n",
    "            x, state_h, state_c = self.lstm(x, training=training)\n",
    "        else:\n",
    "            # 将初始状态传递给LSTM层\n",
    "            x, state_h, state_c = self.lstm(x, initial_state=states, training=training)\n",
    "        \n",
    "        # 将LSTM层的输出通过密集层\n",
    "        x = self.dense(x, training=training)\n",
    "\n",
    "        if return_state:\n",
    "            return x, [state_h, state_c]\n",
    "        else:\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "fa3a9996",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Exception encountered when calling layer 'embedding_13' (type Embedding).\n\n'list' object has no attribute 'dtype'\n\nCall arguments received by layer 'embedding_13' (type Embedding):\n  • inputs=[['tf.Tensor(shape=(), dtype=int32)', 'tf.Tensor(shape=(), dtype=int32)', 'tf.Tensor(shape=(), dtype=int32)', 'tf.Tensor(shape=(), dtype=int32)', 'tf.Tensor(shape=(), dtype=int32)'], ['tf.Tensor(shape=(), dtype=int32)', 'tf.Tensor(shape=(), dtype=int32)', 'tf.Tensor(shape=(), dtype=int32)', 'tf.Tensor(shape=(), dtype=int32)', 'tf.Tensor(shape=(), dtype=int32)']]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/tt/kv93hy8d0l5gkhtlnrmv0vjw0000gn/T/ipykernel_3858/2685460078.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# 3. Call the model to obtain predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# 4. Process the predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/tt/kv93hy8d0l5gkhtlnrmv0vjw0000gn/T/ipykernel_3858/4073620136.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, states, return_state, training)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \"\"\"由于我们正在训练一个文本生成模型，\n\u001b[1;32m     15\u001b[0m         \u001b[0m我们在训练中使用前一个状态\u001b[0m\u001b[0;31m。\u001b[0m\u001b[0m如果没有状态\u001b[0m\u001b[0;31m，\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: Exception encountered when calling layer 'embedding_13' (type Embedding).\n\n'list' object has no attribute 'dtype'\n\nCall arguments received by layer 'embedding_13' (type Embedding):\n  • inputs=[['tf.Tensor(shape=(), dtype=int32)', 'tf.Tensor(shape=(), dtype=int32)', 'tf.Tensor(shape=(), dtype=int32)', 'tf.Tensor(shape=(), dtype=int32)', 'tf.Tensor(shape=(), dtype=int32)'], ['tf.Tensor(shape=(), dtype=int32)', 'tf.Tensor(shape=(), dtype=int32)', 'tf.Tensor(shape=(), dtype=int32)', 'tf.Tensor(shape=(), dtype=int32)', 'tf.Tensor(shape=(), dtype=int32)']]"
     ]
    }
   ],
   "source": [
    "# 1. Instantiate the model\n",
    "model = MyModel(\n",
    "    vocab_size=len(ids_from_chars.get_vocabulary()),\n",
    "    embedding_dim=embedding_dim,\n",
    "    lstm_units=rnn_units)\n",
    "\n",
    "# 2. Prepare input data (example data)\n",
    "input_data = [[1, 2, 3, 4, 5], [6, 7, 8, 9, 10]]  # Example numerical sequences\n",
    "\n",
    "# 3. Call the model to obtain predictions\n",
    "predictions, _ = model(input_data)\n",
    "\n",
    "# 4. Process the predictions\n",
    "print(\"Predictions shape:\", predictions.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "76058156",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel(\n",
    "    # Be sure the vocabulary size matches the `StringLookup` layers.\n",
    "    vocab_size = len(ids_from_chars.get_vocabulary()),\n",
    "    embedding_dim = embedding_dim,\n",
    "    rnn_units = rnn_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "3f7da8c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(63, 100, 78) # (batch_size, sequence_length, vocab_size)\n"
     ]
    }
   ],
   "source": [
    "# Process the dataset\n",
    "for input_example_batch, target_example_batch in dataset.take(1):\n",
    "    example_batch_predictions = model(input_example_batch)\n",
    "    print(\n",
    "        example_batch_predictions.shape,\n",
    "        \"# (batch_size, sequence_length, vocab_size)\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "38431dc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"my_model_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_13 (Embedding)    multiple                  19968     \n",
      "                                                                 \n",
      " lstm_11 (LSTM)              multiple                  0 (unused)\n",
      "                                                                 \n",
      " dense_13 (Dense)            multiple                  0 (unused)\n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19968 (78.00 KB)\n",
      "Trainable params: 19968 (78.00 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "8390795a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_indices = tf.random.categorical(\n",
    "    example_batch_predictions[0],\n",
    "    num_samples = 1\n",
    ")\n",
    "\n",
    "sampled_indices = tf.squeeze(sampled_indices, axis=1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "662f1209",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([58, 48, 71,  5, 47, 47, 44, 55, 52, 30, 56, 18, 31, 14, 28, 31, 51,\n",
       "       32, 34, 16, 64, 61, 53, 21, 21, 70, 13,  2, 38, 47, 27,  0, 66, 13,\n",
       "        7, 37, 60, 65, 30, 76, 48, 76, 27, 77, 74, 43, 39, 53,  9, 33, 37,\n",
       "       68,  4, 61, 65, 63, 65, 50, 52, 69, 17, 32, 14,  5, 46,  8, 28, 45,\n",
       "       11, 52, 57, 28, 74, 39, 51, 70, 55, 15, 70, 76, 61, 65,  9, 38, 71,\n",
       "       70, 61, 37,  0, 18, 77, 17, 16, 19, 42, 47, 12, 74, 49, 58])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "968dc25f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\n",
      "b'ain chalet aspen:\\nhotel location is great - you can walk to restaurants and major attractions.\"\\n\"mou'\n",
      "Next Char Predictions:\n",
      "b'xn\\xe2\\x80\\x94#mmjur<v0=,:=q>\\\\.\\xc2\\xb0{s33\\xe2\\x80\\x93+ dm9[UNK]\\xc3\\xa2+%cz\\xc2\\xb4<\\xe2\\x80\\xa6n\\xe2\\x80\\xa69\\xef\\xb8\\x8f\\xe2\\x80\\x9cies\\'?c\\xc3\\xa9\"{\\xc2\\xb4~\\xc2\\xb4pr\\xc3\\xbc/>,#l&:k)rw:\\xe2\\x80\\x9ceq\\xe2\\x80\\x93u-\\xe2\\x80\\x93\\xe2\\x80\\xa6{\\xc2\\xb4\\'d\\xe2\\x80\\x94\\xe2\\x80\\x93{c[UNK]0\\xef\\xb8\\x8f/.1hm*\\xe2\\x80\\x9cox'\n"
     ]
    }
   ],
   "source": [
    "print('Input:', text_from_ids(input_example_batch[0]).numpy(), sep='\\n')\n",
    "print('Next Char Predictions:', text_from_ids(sampled_indices).numpy(), sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "3e3a95e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "9cce8e4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediciton shape: \n",
      "(63, 100, 78)\n",
      "# (batch_size, sequence_length, vocab_size\n",
      "New loss:         tf.Tensor(4.3574915, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "example_batch_mean_loss = loss(target_example_batch, example_batch_predictions)\n",
    "print(\n",
    "    'Prediciton shape: ',\n",
    "    example_batch_predictions.shape,\n",
    "    '# (batch_size, sequence_length, vocab_size',\n",
    "    sep='\\n'\n",
    ")\n",
    "print('New loss:        ', example_batch_mean_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "e3bedad3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78.06107"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.exp(example_batch_mean_loss).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "34ad0f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "05884abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path where tha checkpoints will be saved\n",
    "checkpoint_path = './training_checkpoints'\n",
    "# Name of the checkpoint file\n",
    "checkpoint_prefix = os.path.join(checkpoint_path, \"ckpt_(epoch)\")\n",
    "\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath = checkpoint_prefix, save_weight_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "1efc17c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "149/149 [==============================] - ETA: 0s - loss: 2.6708INFO:tensorflow:Assets written to: ./training_checkpoints/ckpt_(epoch)/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./training_checkpoints/ckpt_(epoch)/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149/149 [==============================] - 362s 2s/step - loss: 2.6708\n",
      "Epoch 2/10\n",
      "149/149 [==============================] - ETA: 0s - loss: 1.8851INFO:tensorflow:Assets written to: ./training_checkpoints/ckpt_(epoch)/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./training_checkpoints/ckpt_(epoch)/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149/149 [==============================] - 424s 3s/step - loss: 1.8851\n",
      "Epoch 3/10\n",
      "149/149 [==============================] - ETA: 0s - loss: 1.4637INFO:tensorflow:Assets written to: ./training_checkpoints/ckpt_(epoch)/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./training_checkpoints/ckpt_(epoch)/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149/149 [==============================] - 371s 2s/step - loss: 1.4637\n",
      "Epoch 4/10\n",
      "149/149 [==============================] - ETA: 0s - loss: 1.2738INFO:tensorflow:Assets written to: ./training_checkpoints/ckpt_(epoch)/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./training_checkpoints/ckpt_(epoch)/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149/149 [==============================] - 298s 2s/step - loss: 1.2738\n",
      "Epoch 5/10\n",
      "149/149 [==============================] - ETA: 0s - loss: 1.1727INFO:tensorflow:Assets written to: ./training_checkpoints/ckpt_(epoch)/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./training_checkpoints/ckpt_(epoch)/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149/149 [==============================] - 294s 2s/step - loss: 1.1727\n",
      "Epoch 6/10\n",
      "149/149 [==============================] - ETA: 0s - loss: 1.1053INFO:tensorflow:Assets written to: ./training_checkpoints/ckpt_(epoch)/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./training_checkpoints/ckpt_(epoch)/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149/149 [==============================] - 290s 2s/step - loss: 1.1053\n",
      "Epoch 7/10\n",
      "149/149 [==============================] - ETA: 0s - loss: 1.0538INFO:tensorflow:Assets written to: ./training_checkpoints/ckpt_(epoch)/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./training_checkpoints/ckpt_(epoch)/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149/149 [==============================] - 294s 2s/step - loss: 1.0538\n",
      "Epoch 8/10\n",
      "149/149 [==============================] - ETA: 0s - loss: 1.0100INFO:tensorflow:Assets written to: ./training_checkpoints/ckpt_(epoch)/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./training_checkpoints/ckpt_(epoch)/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149/149 [==============================] - 293s 2s/step - loss: 1.0100\n",
      "Epoch 9/10\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.9692INFO:tensorflow:Assets written to: ./training_checkpoints/ckpt_(epoch)/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./training_checkpoints/ckpt_(epoch)/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149/149 [==============================] - 293s 2s/step - loss: 0.9692\n",
      "Epoch 10/10\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.9304INFO:tensorflow:Assets written to: ./training_checkpoints/ckpt_(epoch)/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./training_checkpoints/ckpt_(epoch)/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149/149 [==============================] - 292s 2s/step - loss: 0.9304\n",
      "CPU times: user 2h 32min 36s, sys: 16min 15s, total: 2h 48min 52s\n",
      "Wall time: 53min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "EPOCHS = 3\n",
    "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "a4060890",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneStep(tf.keras.Model):\n",
    "    def __init__(self, model, chars_from_ids, ids_from_chars, temperature=1.0):\n",
    "        super().__init__()\n",
    "        self.temperature = temperature\n",
    "        self.model = model\n",
    "        self.chars_from_ids = chars_from_ids\n",
    "        self.ids_from_chars = ids_from_chars\n",
    "\n",
    "        # Create a mask to prevent \"[UNK]\" from being generated.\n",
    "        skip_ids = self.ids_from_chars([\"[UNK]\"])[:, None]\n",
    "        sparse_mask = tf.SparseTensor(\n",
    "            # Put a -inf at each bad index.\n",
    "            values=[-float(\"inf\")] * len(skip_ids),\n",
    "            indices=skip_ids,\n",
    "            # Match the shape to the vocabulary\n",
    "            dense_shape=[len(ids_from_chars.get_vocabulary())],\n",
    "        )\n",
    "        self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
    "\n",
    "    @tf.function\n",
    "    def generate_one_step(self, inputs, states=None):\n",
    "        # Convert strings to token IDs.\n",
    "        input_chars = tf.strings.unicode_split(inputs, \"UTF-8\")\n",
    "        input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
    "\n",
    "        # Run the model.\n",
    "                # predicted_logits.shape is [batch, char, next_char_logits]\n",
    "        predicted_logits, states = self.model(\n",
    "            inputs=input_ids, states=states, return_state=True\n",
    "        )\n",
    "        # Only use the last prediction.\n",
    "        predicted_logits = predicted_logits[:, -1, :]\n",
    "        predicted_logits = predicted_logits / self.temperature\n",
    "        # Apply the prediction mask: prevent \"[UNK]\" from being generated.\n",
    "        predicted_logits = predicted_logits + self.prediction_mask\n",
    "\n",
    "        # Sample the output logits to generate token IDs.\n",
    "        predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
    "        predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
    "\n",
    "        # Convert from token ids to characters\n",
    "        predicted_chars = self.chars_from_ids(predicted_ids)\n",
    "\n",
    "        # Return the characters and model state.\n",
    "        return predicted_chars, states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "dfc8f4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_step_model = OneStep(model, chars_from_ids, ids_from_chars)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "29f84ca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chateau Roaring Fork:\n",
      "other outside, clean mountain aspen alpss was wonderful...a we will  bring you terry who i spend 3 night for the morning at their many marsel, beds, beds, and gave us right across the street was olde \n",
      "\n",
      "________________________________________________________________________________\n",
      "\n",
      "Run time: 0.35026097297668457\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "states = None\n",
    "next_char = tf.constant(['Chateau Roaring Fork:'])\n",
    "result = [next_char]\n",
    "\n",
    "for n in range(200):\n",
    "    next_char, states = one_step_model.generate_one_step(\n",
    "        next_char, states = states\n",
    "    )\n",
    "    result.append(next_char)\n",
    "\n",
    "result = tf.strings.join(result)\n",
    "end = time.time()\n",
    "print(result[0].numpy().decode('utf-8'), \"\\n\\n\" + \"_\" * 80)\n",
    "print(\"\\nRun time:\", end - start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "29af3db7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[b'limelight hotel is warm brea...the provide suite also, night 4 add end large but it was not on the best hotels a great place to stay. the weekend could comy site four was great for our weekend. from the wonderful places; this well maintenance staff were very good.  staff was outstanding, all night, where more than oded, laundry, i spoky at aspen next trip to aspen crowds... down impercaben lonwe afternoon on the heart of aspen and excredible biking.  the new cunter queent parking based on day several times.\"\\n\"snow queen lodge:\\ni was amazing and extra tjiditions were always made over the tv.  he was beine - and small while sleeping in the one bedroom condo (the bathroom was clean and had been updated to stay and was throughout the lodge the room. the breakfast and costs resorts and both were so clean. if i also read the bellman downstairs.cerence and limelight hotel:\\na better than clean come layoners are indip with plenty on tho bedrooms above.  it was an insult i could town open in charles are availa'\n",
      " b\"limelight hotel:\\nwas amazing service was handled with my hugbablin or us even suggestions on right, we look running around the washer and seaton.  microwave, too and when we saw monages and delightful.  'd he was made up for 5 times every morning to get one of the experience in the modern were the omelets in whenever we weren't easily the bed was coverrit. and historically case to small but same floor room, pickast, frequently little things as the staff were full. the annabelle tables the condo was spectagular in a table place.  the founder chillen, town to now explain. the room was also interestist were incredibly corveniently located and were very good.  there is a short datt reservation om the hotel is in a great location in the job (1. minute walk to ruhe aspen crremply my sister and service. large room was smaller hotel and supple. the staff was event with realsy to the lodge. ski condo was right next to the same, the one would park breamfast informed and the maroon bells (enjoyed my wife and wh\"], shape=(2,), dtype=string) \n",
      "\n",
      "________________________________________________________________________________\n",
      "\n",
      "Run time 2.1422548294067383\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "states = None\n",
    "next_char = tf.constant(['limelight hotel','limelight hotel' ])\n",
    "result = [next_char]\n",
    "\n",
    "for n in range(1000):\n",
    "    next_char, states = one_step_model.generate_one_step(\n",
    "        next_char, states = states\n",
    "    )\n",
    "    result.append(next_char)\n",
    "\n",
    "result = tf.strings.join(result)\n",
    "end = time.time()\n",
    "print(result, '\\n\\n' + \"_\" * 80)\n",
    "print(\"\\nRun time\", end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848e4a04",
   "metadata": {},
   "source": [
    "### Export the generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "37262595",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'one_step_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/tt/kv93hy8d0l5gkhtlnrmv0vjw0000gn/T/ipykernel_3858/2277498741.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# save the one step model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaved_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mone_step_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'one_step'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'one_step_model' is not defined"
     ]
    }
   ],
   "source": [
    "# save the one step model\n",
    "tf.saved_model.save(one_step_model, 'one_step')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3684478",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
